{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gross-convertible",
   "metadata": {},
   "source": [
    "# PreProcessing Demonstration\n",
    "\n",
    "In this notebook, we will explore the PyTorch Dataset class and show how it can be used to handle input images. It should do some light preprocessing to make sure everything is available. \n",
    "\n",
    "Some things to note:\n",
    "* checks to see that there is a 1-to-1 correspondence between the datasets\n",
    "* does the tiling\n",
    "* exports tiles that are extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful trick for loading the directories correction\n",
    "import sys, os\n",
    "from pyprojroot import here\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "# append to path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "from pathlib import Path\n",
    "from src.data.worldfloods.dataset import WorldFloodsDataset\n",
    "from src.data.utils import get_files_in_directory, get_filenames_in_directory\n",
    "\n",
    "# Imports for the transformations\n",
    "import src.preprocess.transformations as transformations\n",
    "# from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "output_image_dir = str(Path(root).joinpath(\"datasets/trials/image/image_tiles/\"))\n",
    "image_files = get_files_in_directory(output_image_dir, \".tif\")\n",
    "\n",
    "output_gt_dir = str(Path(root).joinpath(\"datasets/trials/image/gt_tiles/\"))\n",
    "gt_files = get_files_in_directory(output_gt_dir, \".tif\")\n",
    "\n",
    "image_prefix = \"image_tiles\"\n",
    "gt_prefix = \"gt_tiles\"\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ignored-hughes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from albumentations import Compose\n",
    "\n",
    "# Stacked Transforms\n",
    "tranform_permute = transformations.PermuteChannels()\n",
    "tranform_toTensor = transformations.ToTensor()\n",
    "tranform_oneHotEncoding = transformations.OneHotEncoding(num_classes=3)\n",
    "\n",
    "mega_transform = transformations.Compose([\n",
    "    tranform_permute, \n",
    "    tranform_toTensor, \n",
    "    tranform_oneHotEncoding,\n",
    "    ])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=mega_transform)\n",
    "\n",
    "# pt_ds[1]['image'].shape\n",
    "pt_ds[3]['mask'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-highlight",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-encyclopedia",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "\n",
    "* [ ] Flip\n",
    "* [ ] GaussNoise\n",
    "* [ ] MotionBlur\n",
    "* [ ] Normalize\n",
    "* [ ] PadIfNeeded\n",
    "* [ ] RandomRotate90\n",
    "* [ ] ShiftScaleRotate\n",
    "---\n",
    "* [ ] PerChannel Transformations\n",
    "* [X] ResizeFactor Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dutch-infection",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c32d2d629d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0muse_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mchannel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf_normalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtransform_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pixel_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ml4floods/src/preprocess/worldfloods/normalize.py\u001b[0m in \u001b[0;36mget_normalisation\u001b[0;34m(use_channels)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0ms2_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCHANNELS_CONFIGURATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muse_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0ms2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSENTINEL2_NORMALIZATION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms2_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#  channel stats for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 13"
     ]
    }
   ],
   "source": [
    "from src.preprocess.worldfloods import normalize as wf_normalize\n",
    "\n",
    "# Stacked Transforms\n",
    "transform_permute = transformations.PermuteChannels()\n",
    "transform_toTensor = transformations.ToTensor()\n",
    "# TODO: Check number of classes\n",
    "transform_oneHotEncoding = transformations.OneHotEncoding(num_classes=4) \n",
    "transform_resizeFactor = transformations.ResizeFactor(downsampling_factor=4, always_apply=True, p=1)\n",
    "\n",
    "use_channels = \"all\"\n",
    "channel_mean, channel_std = wf_normalize.get_normalisation(use_channels)\n",
    "transform_normalize = transformations.Normalize(mean=channel_mean, std=channel_std, max_pixel_value=1.0)\n",
    "\n",
    "# DO NOT CHANGE THE ORDER\n",
    "mega_transform = transforms.Compose([\n",
    "    transform_resizeFactor, \n",
    "    transform_permute, \n",
    "    transform_toTensor, \n",
    "    transform_oneHotEncoding,\n",
    "    transform_normalize,\n",
    "    ])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(\n",
    "    image_files, \n",
    "    image_prefix, \n",
    "    gt_prefix, \n",
    "    transforms=mega_transform,\n",
    "    )\n",
    "\n",
    "print(\"image:\", pt_ds[2]['image'].shape)\n",
    "print(\"mask:\", pt_ds[2]['mask'].shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-parcel",
   "metadata": {},
   "source": [
    "---\n",
    "* [ ] use a numpy array for every trasnformation other than \"ToTensor\"\n",
    "* [ ] check to make sure that the normalize thing works for the special sensor\n",
    "* [ ] check channeljitter PerRotation\n",
    "* [ ] do a notebook showing what the transformation pictures look like\n",
    "* [ ] discuss augmentation, adversarial training, etc content for ppt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-priority",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 13 is out of bounds for axis 0 with size 13",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-08328c499a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0muse_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mchannel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf_normalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_normalisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtransform_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalizeCustom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pixel_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ml4floods/src/preprocess/worldfloods/normalize.py\u001b[0m in \u001b[0;36mget_normalisation\u001b[0;34m(use_channels)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0ms2_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCHANNELS_CONFIGURATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muse_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0ms2_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSENTINEL2_NORMALIZATION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms2_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#  channel stats for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 13 is out of bounds for axis 0 with size 13"
     ]
    }
   ],
   "source": [
    "from src.preprocess.worldfloods import normalize as wf_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalization -------------\n",
    "\n",
    "use_channels = \"all\"\n",
    "channel_mean, channel_std = wf_normalize.get_normalisation(use_channels)\n",
    "transform_normalize = transformations.NormalizeCustom(mean=channel_mean, std=channel_std, max_pixel_value=1.0)\n",
    "\n",
    "# pt_ds_norm = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=transform_gauss)\n",
    "pt_ds_norm = transform_normalize(input_data=pt_ds[1])\n",
    "pt_ds_norm['image'].shape\n",
    "\n",
    "# Gaussian Noise -------------\n",
    "\n",
    "# transform_gauss = transformations.GaussNoise(var_limit=(1e-6, 1e-3), p=1)\n",
    "# pt_ds_gauss = transform_gauss(image=pt_ds[1]['image'])\n",
    "\n",
    "# print(pt_ds_gauss['image'][:,:,6].shape)\n",
    "# print(np.min(pt_ds_gauss['image'][:,:,6]))\n",
    "# print(np.max(pt_ds_gauss['image'][:,:,6]))\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "# ax[0].imshow(pt_ds[1]['image'][:,:,6])\n",
    "# ax[1].imshow(pt_ds_gauss['image'][:,:,6])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-laser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4fl_py38]",
   "language": "python",
   "name": "conda-env-ml4fl_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
