{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inclusive-emphasis",
   "metadata": {},
   "source": [
    "# PreProcessing Demonstration\n",
    "\n",
    "In this notebook, we will explore the PyTorch Dataset class and show how it can be used to handle input images. It should do some light preprocessing to make sure everything is available. \n",
    "\n",
    "Some things to note:\n",
    "* checks to see that there is a 1-to-1 correspondence between the datasets\n",
    "* does the tiling\n",
    "* exports tiles that are extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful trick for loading the directories correction\n",
    "import sys, os\n",
    "from pyprojroot import here\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "# append to path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "from pathlib import Path\n",
    "from src.data.worldfloods.dataset import WorldFloodsDataset\n",
    "from src.data.utils import get_files_in_directory, get_filenames_in_directory\n",
    "\n",
    "# Imports for the transformations\n",
    "import src.preprocess.transformations as transformations\n",
    "# from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "output_image_dir = str(Path(root).joinpath(\"datasets/trials/image/image_tiles/\"))\n",
    "image_files = get_files_in_directory(output_image_dir, \".tif\")\n",
    "\n",
    "output_gt_dir = str(Path(root).joinpath(\"datasets/trials/image/gt_tiles/\"))\n",
    "gt_files = get_files_in_directory(output_gt_dir, \".tif\")\n",
    "\n",
    "image_prefix = \"image_tiles\"\n",
    "gt_prefix = \"gt_tiles\"\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# from albumentations import Compose\n",
    "\n",
    "# Stacked Transforms\n",
    "tranform_permute = transformations.PermuteChannels()\n",
    "tranform_toTensor = transformations.ToTensor()\n",
    "tranform_oneHotEncoding = transformations.OneHotEncoding(num_classes=3)\n",
    "\n",
    "mega_transform = transformations.Compose([\n",
    "    tranform_permute, \n",
    "    tranform_toTensor, \n",
    "    tranform_oneHotEncoding,\n",
    "    ])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=mega_transform)\n",
    "\n",
    "# pt_ds[1]['image'].shape\n",
    "pt_ds[3]['mask'].shape\n"
   ]
  },
  {
   "source": [
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Transformations\n",
    "\n",
    "* [ ] Flip\n",
    "* [ ] GaussNoise\n",
    "* [ ] MotionBlur\n",
    "* [ ] Normalize\n",
    "* [ ] PadIfNeeded\n",
    "* [ ] RandomRotate90\n",
    "* [ ] ShiftScaleRotate\n",
    "---\n",
    "* [ ] PerChannel Transformations\n",
    "* [X] ResizeFactor Transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">>>>>>>>> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2f6e2615af48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ml4floods/src/data/worldfloods/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Apply transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# x, y = res[\"image\"], res[\"mask\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml4f_dj/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/ml4floods/src/preprocess/transformations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_data, interpolation, **params)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         new_size = np.round(np.array(image.shape[:2]) / self.downsampling_factor).astype(\n\u001b[1;32m    245\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Stacked Transforms\n",
    "transform_permute = transformations.PermuteChannels()\n",
    "transform_toTensor = transformations.ToTensor()\n",
    "# TODO: Check number of classes\n",
    "transform_oneHotEncoding = transformations.OneHotEncoding(num_classes=4) \n",
    "transform_resizeFactor = transformations.ResizeFactor(downsampling_factor=4, always_apply=True, p=1)\n",
    "\n",
    "use_channels = \"all\"\n",
    "channel_mean, channel_std = wf_normalize.get_normalisation(use_channels)\n",
    "transform_normalize = transformations.Normalize(mean=channel_mean, std=channel_std, max_pixel_value=1.0)\n",
    "\n",
    "# DO NOT CHANGE THE ORDER\n",
    "mega_transform = transforms.Compose([\n",
    "    transform_resizeFactor, \n",
    "    transform_permute, \n",
    "    transform_toTensor, \n",
    "    transform_oneHotEncoding,\n",
    "    transform_normalize,\n",
    "    ])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(\n",
    "    image_files, \n",
    "    image_prefix, \n",
    "    gt_prefix, \n",
    "    transforms=mega_transform,\n",
    "    )\n",
    "\n",
    "print(\"image:\", pt_ds[2]['image'].shape)\n",
    "print(\"mask:\", pt_ds[2]['mask'].shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "---\n",
    "* [ ] use a numpy array for every trasnformation other than \"ToTensor\"\n",
    "* [ ] check to make sure that the normalize thing works for the special sensor\n",
    "* [ ] check channeljitter PerRotation\n",
    "* [ ] do a notebook showing what the transformation pictures look like\n",
    "* [ ] discuss augmentation, adversarial training, etc content for ppt\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from src.preprocess.worldfloods import normalize as wf_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalization -------------\n",
    "\n",
    "use_channels = \"all\"\n",
    "channel_mean, channel_std = wf_normalize.get_normalisation(use_channels)\n",
    "transform_normalize = transformations.NormalizeCustom(mean=channel_mean, std=channel_std, max_pixel_value=1.0)\n",
    "\n",
    "# pt_ds_norm = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=transform_gauss)\n",
    "pt_ds_norm = transform_normalize(input_data=pt_ds[1])\n",
    "pt_ds_norm['image'].shape\n",
    "\n",
    "# Gaussian Noise -------------\n",
    "\n",
    "# transform_gauss = transformations.GaussNoise(var_limit=(1e-6, 1e-3), p=1)\n",
    "# pt_ds_gauss = transform_gauss(image=pt_ds[1]['image'])\n",
    "\n",
    "# print(pt_ds_gauss['image'][:,:,6].shape)\n",
    "# print(np.min(pt_ds_gauss['image'][:,:,6]))\n",
    "# print(np.max(pt_ds_gauss['image'][:,:,6]))\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "# ax[0].imshow(pt_ds[1]['image'][:,:,6])\n",
    "# ax[1].imshow(pt_ds_gauss['image'][:,:,6])\n",
    "# plt.show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 128, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}