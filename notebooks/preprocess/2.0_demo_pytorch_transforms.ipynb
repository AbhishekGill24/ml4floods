{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inclusive-emphasis",
   "metadata": {},
   "source": [
    "# PreProcessing Demonstration\n",
    "\n",
    "In this notebook, we will explore the PyTorch Dataset class and show how it can be used to handle input images. It should do some light preprocessing to make sure everything is available. \n",
    "\n",
    "Some things to note:\n",
    "* checks to see that there is a 1-to-1 correspondence between the datasets\n",
    "* does the tiling\n",
    "* exports tiles that are extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful trick for loading the directories correction\n",
    "import sys, os\n",
    "from pyprojroot import here\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".here\"])\n",
    "# append to path\n",
    "sys.path.append(str(here()))\n",
    "\n",
    "from pathlib import Path\n",
    "from src.data.worldfloods.dataset import WorldFloodsDataset\n",
    "from src.data.utils import get_files_in_directory, get_filenames_in_directory\n",
    "\n",
    "\n",
    "output_image_dir = str(Path(root).joinpath(\"datasets/trials/image/image_tiles/\"))\n",
    "image_files = get_files_in_directory(output_image_dir, \".tif\")\n",
    "\n",
    "output_gt_dir = str(Path(root).joinpath(\"datasets/trials/image/gt_tiles/\"))\n",
    "gt_files = get_files_in_directory(output_gt_dir, \".tif\")\n",
    "\n",
    "image_prefix = \"image_tiles\"\n",
    "gt_prefix = \"gt_tiles\"\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for the transformations\n",
    "\n",
    "import src.preprocess.transformations as transformations\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "-----------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "\n",
    "# Stacked Transforms\n",
    "tranform_permute = transformations.PermuteChannels()\n",
    "tranform_toTensor = transformations.ToTensor()\n",
    "tranform_oneHotEncoding = transformations.OneHotEncoding(num_classes=3)\n",
    "\n",
    "mega_transform = transforms.Compose([tranform_permute, tranform_toTensor, tranform_oneHotEncoding])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=mega_transform)\n",
    "\n",
    "pt_ds[1]['mask'].shape"
   ]
  },
  {
   "source": [
    "--------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Transformations\n",
    "\n",
    "* [ ] Flip\n",
    "* [ ] GaussNoise\n",
    "* [ ] MotionBlur\n",
    "* [ ] Normalize\n",
    "* [ ] PadIfNeeded\n",
    "* [ ] RandomRotate90\n",
    "* [ ] ShiftScaleRotate\n",
    "---\n",
    "* [ ] PerChannel Transformations\n",
    "* [ ] ResizeFactor Transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32, 32, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Stacked Transforms\n",
    "transform_permute = transformations.PermuteChannels()\n",
    "transform_toTensor = transformations.ToTensor()\n",
    "transform_oneHotEncoding = transformations.OneHotEncoding(num_classes=3)\n",
    "transform_resizeFactor = transformations.ResizeFactor(downsampling_factor=4, always_apply=True, p=1)\n",
    "\n",
    "# DO NOT CHANGE THE ORDER\n",
    "mega_transform = transforms.Compose([transform_resizeFactor, transform_permute, transform_toTensor, transform_oneHotEncoding])\n",
    "\n",
    "pt_ds = WorldFloodsDataset(image_files, image_prefix, gt_prefix, transforms=transform_resizeFactor)\n",
    "\n",
    "pt_ds[2]['image'].shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "---\n",
    "* [ ] use a numpy array for every trasnformation other than \"ToTensor\"\n",
    "* [ ] check to make sure that the normalize thing works for the special sensor\n",
    "* [ ] check channeljitter PerRotation\n",
    "* [ ] do a notebook showing what the transformation pictures look like\n",
    "* [ ] discuss augmentation, adversarial training, etc content for ppt\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}